{
    "4": {
      "inputs": {
        "ckpt_name": "sd_xl_base_1.0.safetensors"
      },
      "class_type": "CheckpointLoaderSimple"
    },
    "5": {
      "inputs": {
        "width": 1024,
        "height": 1024,
        "batch_size": 1
      },
      "class_type": "EmptyLatentImage"
    },
    "6": {
      "inputs": {
        "text": "",
        "clip": [
          "4",
          1
        ]
      },
      "class_type": "CLIPTextEncode"
    },
    "7": {
      "inputs": {
        "text": "",
        "clip": [
          "4",
          1
        ]
      },
      "class_type": "CLIPTextEncode"
    },
    "10": {
      "inputs": {
        "add_noise": "enable",
        "noise_seed": 0,
        "steps": 0,
        "cfg": 0,
        "sampler_name": "",
        "scheduler": "",
        "start_at_step": 0,
        "end_at_step": 0,
        "return_with_leftover_noise": "enable",
        "model": [
          "4",
          0
        ],
        "positive": [
          "6",
          0
        ],
        "negative": [
          "7",
          0
        ],
        "latent_image": [
          "5",
          0
        ]
      },
      "class_type": "KSamplerAdvanced"
    },
    "11": {
      "inputs": {
        "add_noise": "disable",
        "noise_seed": 0,
        "steps": 0,
        "cfg": 0,
        "sampler_name": "",
        "scheduler": "",
        "start_at_step": 0,
        "end_at_step": 10000,
        "return_with_leftover_noise": "disable",
        "model": [
          "12",
          0
        ],
        "positive": [
          "15",
          0
        ],
        "negative": [
          "16",
          0
        ],
        "latent_image": [
          "10",
          0
        ]
      },
      "class_type": "KSamplerAdvanced"
    },
    "12": {
      "inputs": {
        "ckpt_name": "sd_xl_refiner_1.0.safetensors"
      },
      "class_type": "CheckpointLoaderSimple"
    },
    "15": {
      "inputs": {
        "text": "",
        "clip": [
          "12",
          1
        ]
      },
      "class_type": "CLIPTextEncode"
    },
    "16": {
      "inputs": {
        "text": "",
        "clip": [
          "12",
          1
        ]
      },
      "class_type": "CLIPTextEncode"
    },
    "17": {
      "inputs": {
        "samples": [
          "11",
          0
        ],
        "vae": [
          "12",
          2
        ]
      },
      "class_type": "VAEDecode"
    },
    "19": {
      "inputs": {
        "filename_prefix": "",
        "images": [
          "17",
          0
        ]
      },
      "class_type": "SaveImage"
    }
}