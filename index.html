<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Generator</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        input, button {
            margin: 10px;
            padding: 10px;
            font-size: 16px;
        }
        img {
            margin-top: 20px;
            max-width: 100%;
            height: auto;
        }
        #progressBar {
            width: 10%;
            height: 80px;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <h1>Generator obrazów</h1>
    <input type="text" id="uid" placeholder="UID" />
    <label for="modelSelect">Model</label>
    <select id="modelSelect">
        <option value="sd3.5_large_fp8_scaled.safetensors">Stable Diffusion 3.5 Large (fp8)</option>
        <option value="sd_xl_base_1.0.safetensors">Stable Diffusion XL</option>
        <option value="sd_xl_turbo_1.0_fp16.safetensors">Stable Diffusion XL Turbo (fp16)</option>
    </select>
    <label for="positivePrompt">Positive Prompt</label>
    <input type="text" id="positivePrompt" placeholder="Elvish sword" />
    <label for="negativePrompt">Negative Prompt</label>
    <input type="text" id="negativePrompt" placeholder="Bad" />
    <label for="samplerSelect">Sampler</label>
    <select id="samplerSelect">
        <option value="euler">euler</option>
        <option value="euler_ancestral">euler_ancestral</option>
    </select>
    <label for="cfgInput">CFG</label>
    <input type="number" id="cfgInput" min="1" max="20" step="0.1" value="4" />
    <label for="stepsInput">Steps</label>
    <input type="number" id="stepsInput" min="20" max="70" step="1" value="50" />
    <label id= "stepsRefineLabel" for="stepsRefineInput" hidden="true">Refiner Steps</label>
    <input type="number" id="stepsRefineInput" min="20" max="70" step="1" value="50" hidden="true" />
    <progress id="progressBar" value="0" max="100"></progress>
    <button id="submitButton">Prześlij</button>
    <div id="output"></div>
	<button id="reloadGallery">Załaduj obrazy</button>
	<div id="gallery"></div>
	<div id="imageModal" style="display: none; position: fixed; top: 0; left: 0; width: 100%; height: 100%; background-color: rgba(0, 0, 0, 0.8); justify-content: center; align-items: center; z-index: 1000;">
		<img id="modalImage" style="max-width: 90%; max-height: 90%; border: 2px solid white; border-radius: 10px;" />
	</div>

    <script type="module">
        import { Client } from "https://cdn.jsdelivr.net/npm/@stable-canvas/comfyui-client@latest/dist/main.module.mjs";

        // Galeria posortowana po dacie (od najnowszych)
		// Kontakt z ComfyUI powinien zacząć działać
		// Zastanowić się nad WebSocket w przypadku problemów
        // Przenieść workflow do plików
        // Stała struktura workflow. Wywołanie changeModel pobiera plik workflow, ustawia dany jako workflow i ustawia zmienne, które będą przekazywane do validateInputs przez argumenty (limity oraz które inputy walidować)
		// Wykonać FrontEnd jakiś ładny

        // Inicjalizacja klienta
        const client = new Client({
            api_host: "localhost:8000", // Adres i port serwera ComfyUI
        });

        try {
			client.connect()
   			console.log('Connected to ComfyUI server');
		} catch (error) {
    		console.error('Failed to connect to ComfyUI server:', error);
		}

        function validateInputs() {
            const positivePrompt = document.getElementById('positivePrompt').value.trim();
            const cfgInput = parseFloat(document.getElementById('cfgInput').value);
            const stepsInput = parseInt(document.getElementById('stepsInput').value);
            const stepsRefineInput = parseInt(document.getElementById('stepsRefineInput').value);
            var stepsMaxLimit = 140

            if (document.getElementById('modelSelect').value === 'sd_xl_turbo_1.0_fp16.safetensors') {
                stepsMaxLimit = 10
            }

            if (!positivePrompt) {
                alert('Positive Prompt jest wymagany.');
                return;
            }

            if (isNaN(cfgInput) || cfgInput < 1.0 || cfgInput > 20.0) {
                alert('CFG musi być liczbą pomiędzy 1.0 a 20.0.');
                return;
            }

            if (isNaN(stepsInput) || stepsInput < 1 || stepsInput > stepsMaxLimit || !Number.isInteger(stepsInput)) {
                alert('Steps musi być liczbą całkowitą pomiędzy 1 a ' + stepsMaxLimit + '.');
                return;
            }

            if (isNaN(stepsRefineInput) || stepsRefineInput < 1 || stepsRefineInput > 100 || !Number.isInteger(stepsRefineInput)) {
                alert('Refiner Steps musi być liczbą całkowitą pomiędzy 1 a 100.');
                return;
            }

            setWorkflow();
        }

        function updateProgressBar(value, max) {
            const progressBar = document.getElementById('progressBar');
            const percentage = (value / max) * 100;
            progressBar.value = percentage;
        }

        function changeModel() {
            if (document.getElementById('modelSelect').value === 'sd_xl_base_1.0.safetensors') {
                document.getElementById('stepsRefineInput').hidden = false;
                document.getElementById('stepsRefineLabel').hidden = false;
            }
            if (document.getElementById('modelSelect').value === 'sd3.5_large_fp8_scaled.safetensors' || document.getElementById('modelSelect').value === 'sd_xl_turbo_1.0_fp16.safetensors') {
                document.getElementById('stepsRefineInput').hidden = true;
                document.getElementById('stepsRefineLabel').hidden = true;
            }
        }

        function setWorkflow() {
            const promptP = document.getElementById('positivePrompt').value;
            const promptN = document.getElementById('negativePrompt').value;
            const cfg = parseFloat(document.getElementById('cfgInput').value);
            const steps = parseInt(document.getElementById('stepsInput').value);
            const stepsRefine = parseInt(document.getElementById('stepsRefineInput').value);
            const sampler = document.getElementById('samplerSelect').value;
            const uid = document.getElementById('uid').value.trim();

            const workflowSDXLTurbo = {
                "5": {
                  "inputs": {
                    "width": 512,
                    "height": 512,
                    "batch_size": 1
                  },
                  "class_type": "EmptyLatentImage"
                },
                "6": {
                  "inputs": {
                    "text": promptP,
                    "clip": [
                      "20",
                      1
                    ]
                  },
                  "class_type": "CLIPTextEncode",
                  "_meta": {
                    "title": "CLIP Text Encode (Prompt)"
                  }
                },
                "7": {
                  "inputs": {
                    "text": promptN,
                    "clip": [
                      "20",
                      1
                    ]
                  },
                  "class_type": "CLIPTextEncode"
                },
                "8": {
                  "inputs": {
                    "samples": [
                      "13",
                      0
                    ],
                    "vae": [
                      "20",
                      2
                    ]
                  },
                  "class_type": "VAEDecode"
                },
                "13": {
                  "inputs": {
                    "add_noise": true,
                    "noise_seed": 0,
                    "cfg": cfg,
                    "model": [
                      "20",
                      0
                    ],
                    "positive": [
                      "6",
                      0
                    ],
                    "negative": [
                      "7",
                      0
                    ],
                    "sampler": [
                      "14",
                      0
                    ],
                    "sigmas": [
                      "22",
                      0
                    ],
                    "latent_image": [
                      "5",
                      0
                    ]
                  },
                  "class_type": "SamplerCustom"
                },
                "14": {
                  "inputs": {
                    "sampler_name": sampler
                  },
                  "class_type": "KSamplerSelect",
                },
                "20": {
                  "inputs": {
                    "ckpt_name": "sd_xl_turbo_1.0_fp16.safetensors"
                  },
                  "class_type": "CheckpointLoaderSimple"
                },
                "22": {
                  "inputs": {
                    "steps": steps,
                    "denoise": 1,
                    "model": [
                      "20",
                      0
                    ]
                  },
                  "class_type": "SDTurboScheduler"
                },
                "19": {
                  "inputs": {
                    "filename_prefix": '${uid}\\sdxlturbo',
                    "images": [
                      "8",
                      0
                    ]
                  },
                  "class_type": "SaveImage"
                }
            }

            const workflowSDXL = {
                "4": {
                  "inputs": {
                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                  },
                  "class_type": "CheckpointLoaderSimple"
                },
                "5": {
                  "inputs": {
                    "width": 1024,
                    "height": 1024,
                    "batch_size": 1
                  },
                  "class_type": "EmptyLatentImage"
                },
                "6": {
                  "inputs": {
                    "text": promptP,
                    "clip": [
                      "4",
                      1
                    ]
                  },
                  "class_type": "CLIPTextEncode"
                },
                "7": {
                  "inputs": {
                    "text": promptN,
                    "clip": [
                      "4",
                      1
                    ]
                  },
                  "class_type": "CLIPTextEncode"
                },
                "10": {
                  "inputs": {
                    "add_noise": "enable",
                    "noise_seed": 721897303308196,
                    "steps": stepsRefine+steps,
                    "cfg": cfg,
                    "sampler_name": sampler,
                    "scheduler": "normal",
                    "start_at_step": 0,
                    "end_at_step": steps,
                    "return_with_leftover_noise": "enable",
                    "model": [
                      "4",
                      0
                    ],
                    "positive": [
                      "6",
                      0
                    ],
                    "negative": [
                      "7",
                      0
                    ],
                    "latent_image": [
                      "5",
                      0
                    ]
                  },
                  "class_type": "KSamplerAdvanced"
                },
                "11": {
                  "inputs": {
                    "add_noise": "disable",
                    "noise_seed": 0,
                    "steps": stepsRefine+steps,
                    "cfg": cfg,
                    "sampler_name": sampler,
                    "scheduler": "normal",
                    "start_at_step": steps,
                    "end_at_step": 10000,
                    "return_with_leftover_noise": "disable",
                    "model": [
                      "12",
                      0
                    ],
                    "positive": [
                      "15",
                      0
                    ],
                    "negative": [
                      "16",
                      0
                    ],
                    "latent_image": [
                      "10",
                      0
                    ]
                  },
                  "class_type": "KSamplerAdvanced"
                },
                "12": {
                  "inputs": {
                    "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                  },
                  "class_type": "CheckpointLoaderSimple"
                },
                "15": {
                  "inputs": {
                    "text": promptP,
                    "clip": [
                      "12",
                      1
                    ]
                  },
                  "class_type": "CLIPTextEncode"
                },
                "16": {
                  "inputs": {
                    "text": promptN,
                    "clip": [
                      "12",
                      1
                    ]
                  },
                  "class_type": "CLIPTextEncode"
                },
                "17": {
                  "inputs": {
                    "samples": [
                      "11",
                      0
                    ],
                    "vae": [
                      "12",
                      2
                    ]
                  },
                  "class_type": "VAEDecode"
                },
                "19": {
                  "inputs": {
                    "filename_prefix": '${uid}\\sdxl',
                    "images": [
                      "17",
                      0
                    ]
                  },
                  "class_type": "SaveImage"
                }
            }
        
            const workflowSD35 = {
                "3": {
                    "class_type": "KSampler",
                    "inputs": {
                        "cfg": cfg,
                        "denoise": 1,
                        "latent_image": ["5", 0],
                        "model": ["4", 0],
                        "negative": ["7", 0],
                        "positive": ["6", 0],
                        "sampler_name": sampler,
                        "scheduler": "normal",
                        "seed": 8566257,
                        "steps": steps
                    }
                },
                "4": {
                    "class_type": "CheckpointLoaderSimple",
                    "inputs": {
                        "ckpt_name": "sd3.5_large_fp8_scaled.safetensors"
                    }
                },
                "5": {
                    "class_type": "EmptyLatentImage",
                    "inputs": {
                        "batch_size": 1,
                        "height": 1024,
                        "width": 1024
                    }
                },
                "6": {
                    "class_type": "CLIPTextEncode",
                    "inputs": {
                        "clip": ["4", 1],
                        "text": promptP
                    }
                },
                "7": {
                    "class_type": "CLIPTextEncode",
                    "inputs": {
                        "clip": ["4", 1],
                        "text": promptN
                    }
                },
                "8": {
                    "class_type": "VAEDecode",
                    "inputs": {
                        "samples": ["3", 0],
                        "vae": ["4", 2]
                    }
                },
                "9": {
                  "inputs": {
                    "filename_prefix": '${uid}\\sd35',
                    "images": [
                      "8",
                      0
                    ]
                  },
                  "class_type": "SaveImage"
                }
            }
            if (document.getElementById('modelSelect').value === 'sd_xl_base_1.0.safetensors') {
                generateImage(workflowSDXL);
            }
            if (document.getElementById('modelSelect').value === 'sd3.5_large_fp8_scaled.safetensors') {
                generateImage(workflowSD35);
            }
            if (document.getElementById('modelSelect').value === 'sd_xl_turbo_1.0_fp16.safetensors') {
                generateImage(workflowSDXLTurbo);
            }
        }
        async function generateImage(workflow) {
            try {
                // Wysłanie zapytania do kolejki serwera ComfyUI
				console.log('Sending workflow to ComfyUI:', workflow);
                const result = await Promise.race([
    		        client.enqueue(workflow, {
    		            progress: ({ max, value }) => updateProgressBar(value, max),
    		        }),
    		        new Promise((_, reject) =>
    		            setTimeout(() => reject(new Error('Request timed out')), 10000) // 10-second timeout
    		        ),
    		    ]);

				console.log('Result received from ComfyUI:', result);
            
                // Sprawdzenie, czy odpowiedź zawiera dane obrazu
                if (!result || !result.images || result.images.length === 0) {
                    throw new Error('No image data returned from the server.');
                }
                console.log(result)
                // Wydobycie adresu URL obrazu z odpowiedzi
                const imageUrl = result.images[0].data;

				console.log('Image URL:', imageUrl);
            
                const img = document.createElement('img');
                img.src = imageUrl;
            
                // Obsługa błędów
                img.onerror = () => {
                    alert('Failed to load the generated image. Please check the server response.');
                };
            
                // Wyświetlenie nowego obrazu
                const outputDiv = document.getElementById('output');
                outputDiv.innerHTML = '';
                outputDiv.appendChild(img);
            } catch (error) {
                console.error('Error generating image:', error);
                alert('Failed to generate image. Check the console for details.');
            }
        }

        window.loadImages = async function(directory) {
    	    try {
    	        const response = await fetch(directory);
    	        if (!response.ok) {
    	            throw new Error(`Failed to load directory: ${response.statusText}`);
    	        }
			
    	        const html = await response.text();
    	        const parser = new DOMParser();
    	        const doc = parser.parseFromString(html, 'text/html');
			
    	        // Znajdź wszystkie linki do plików w katalogu
    	        const links = Array.from(doc.querySelectorAll('a'))
    	            .map(link => link.getAttribute('href'))
    	            .filter(href => /\.png$/i.test(href)); // Filtruj tylko obrazy
			
    	        const outputDiv = document.getElementById('gallery');
    	        outputDiv.innerHTML = ''; // Wyczyść poprzednie obrazy
			
    	        links.forEach(file => {
    	            const img = document.createElement('img');
    	            img.src = `${directory}/${file}`;
    	            img.alt = file;
    	            img.style.margin = '10px';
    	            img.style.maxWidth = '200px';
    	            img.style.height = 'auto';

					// Add click event to open the modal
					img.addEventListener('click', () => {
						const modal = document.getElementById('imageModal');
						const modalImage = document.getElementById('modalImage');
						modalImage.src = img.src; // Set the modal image source to the clicked image
						modal.style.display = 'flex'; // Show the modal
					});

					// Close modal when clicking outside the image
					document.getElementById('imageModal').addEventListener('click', (event) => {
					    const modal = document.getElementById('imageModal');
					    const modalImage = document.getElementById('modalImage');
					
					    // Close the modal only if the click is outside the image
					    if (event.target !== modalImage) {
					        modal.style.display = 'none';
					    }
					});

    	            outputDiv.appendChild(img);
    	        });
    	    } catch (error) {
    	        console.error('Error loading images:', error);
    	        alert('Nie udało się załadować obrazów.');
    	    }
    	}

        //document.getElementById('submitButton').addEventListener('click', validateInputs);
		document.getElementById('submitButton').addEventListener('click', () => {
    		validateInputs();
		});
        document.getElementById('modelSelect').addEventListener('change', changeModel);
		document.getElementById('reloadGallery').addEventListener('click', () => {
			const uid = document.getElementById('uid').value.trim();
			loadImages(`http://localhost/gallery/${uid}`);
		});
    </script>
</body>
</html>