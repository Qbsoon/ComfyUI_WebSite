<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Generator</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        input, button {
            margin: 10px;
            padding: 10px;
            font-size: 16px;
        }
        img {
            margin-top: 20px;
            max-width: 100%;
            height: auto;
        }
        #progressBar {
            width: 10%;
            height: 80px;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <h1>Generator obrazów</h1>
    <label for="modelSelect">Model</label>
    <select id="modelSelect">
        <option value="sd3.5_large_fp8_scaled.safetensors">Stable Diffusion 3.5 Large (fp8)</option>
        <option value="sd_xl_base_1.0.safetensors">Stable Diffusion XL</option>
        <option value="sd_xl_turbo_1.0_fp16.safetensors">Stable Diffusion XL Turbo (fp16)</option>
    </select>
    <label for="positivePrompt">Positive Prompt</label>
    <input type="text" id="positivePrompt" placeholder="Elvish sword" />
    <label for="negativePrompt">Negative Prompt</label>
    <input type="text" id="negativePrompt" placeholder="Bad" />
    <label for="samplerSelect">Sampler</label>
    <select id="samplerSelect">
        <option value="euler">euler</option>
        <option value="euler_ancestral">euler_ancestral</option>
    </select>
    <label for="cfgInput">CFG</label>
    <input type="number" id="cfgInput" min="1" max="20" step="0.1" value="4" />
    <label for="stepsInput">Steps</label>
    <input type="number" id="stepsInput" min="20" max="70" step="1" value="50" />
    <label id= "stepsRefineLabel" for="stepsRefineInput" hidden="true">Refiner Steps</label>
    <input type="number" id="stepsRefineInput" min="20" max="70" step="1" value="50" hidden="true" />
    <progress id="progressBar" value="0" max="100"></progress>
    <button id="submitButton">Prześlij</button>
    <div id="output"></div>

    <script type="module">
        import { Client } from "https://cdn.jsdelivr.net/npm/@stable-canvas/comfyui-client@latest/dist/main.module.mjs";

        // Postawić na XAMPP z zaimplementowanym zapisywaniem do katalogu na podstawie otrzymanej ścieżki
        // I galerią posortowaną po dacie

        // Inicjalizacja klienta
        const client = new Client({
            api_host: "192.168.1.84:8000", // Adres i port serwera ComfyUI
        });

        // Połączenie z serwerem ComfyUI
        client.connect();

        function validateInputs() {
            const positivePrompt = document.getElementById('positivePrompt').value.trim();
            const cfgInput = parseFloat(document.getElementById('cfgInput').value);
            const stepsInput = parseInt(document.getElementById('stepsInput').value);
            const stepsRefineInput = parseInt(document.getElementById('stepsRefineInput').value);
            var stepsMaxLimit = 140

            if (document.getElementById('modelSelect').value === 'sd_xl_turbo_1.0_fp16.safetensors') {
                stepsMaxLimit = 10
            }

            if (!positivePrompt) {
                alert('Positive Prompt jest wymagany.');
                return;
            }

            if (isNaN(cfgInput) || cfgInput < 1.0 || cfgInput > 20.0) {
                alert('CFG musi być liczbą pomiędzy 1.0 a 20.0.');
                return;
            }

            if (isNaN(stepsInput) || stepsInput < 1 || stepsInput > stepsMaxLimit || !Number.isInteger(stepsInput)) {
                alert('Steps musi być liczbą całkowitą pomiędzy 1 a ' + stepsMaxLimit + '.');
                return;
            }

            if (isNaN(stepsRefineInput) || stepsRefineInput < 1 || stepsRefineInput > 100 || !Number.isInteger(stepsRefineInput)) {
                alert('Refiner Steps musi być liczbą całkowitą pomiędzy 1 a 100.');
                return;
            }

            setWorkflow();
        }

        function updateProgressBar(value, max) {
            const progressBar = document.getElementById('progressBar');
            const percentage = (value / max) * 100;
            progressBar.value = percentage;
        }

        function changeModel() {
            if (document.getElementById('modelSelect').value === 'sd_xl_base_1.0.safetensors') {
                document.getElementById('stepsRefineInput').hidden = false;
                document.getElementById('stepsRefineLabel').hidden = false;
            }
            if (document.getElementById('modelSelect').value === 'sd3.5_large_fp8_scaled.safetensors' || document.getElementById('modelSelect').value === 'sd_xl_turbo_1.0_fp16.safetensors') {
                document.getElementById('stepsRefineInput').hidden = true;
                document.getElementById('stepsRefineLabel').hidden = true;
            }
        }

        function setWorkflow() {
            const promptP = document.getElementById('positivePrompt').value;
            const promptN = document.getElementById('negativePrompt').value;
            const cfg = parseFloat(document.getElementById('cfgInput').value);
            const steps = parseInt(document.getElementById('stepsInput').value);
            const stepsRefine = parseInt(document.getElementById('stepsRefineInput').value);
            const sampler = document.getElementById('samplerSelect').value;

            const workflowSDXLTurbo = {
                "5": {
                  "inputs": {
                    "width": 512,
                    "height": 512,
                    "batch_size": 1
                  },
                  "class_type": "EmptyLatentImage"
                },
                "6": {
                  "inputs": {
                    "text": promptP,
                    "clip": [
                      "20",
                      1
                    ]
                  },
                  "class_type": "CLIPTextEncode",
                  "_meta": {
                    "title": "CLIP Text Encode (Prompt)"
                  }
                },
                "7": {
                  "inputs": {
                    "text": promptN,
                    "clip": [
                      "20",
                      1
                    ]
                  },
                  "class_type": "CLIPTextEncode"
                },
                "8": {
                  "inputs": {
                    "samples": [
                      "13",
                      0
                    ],
                    "vae": [
                      "20",
                      2
                    ]
                  },
                  "class_type": "VAEDecode"
                },
                "13": {
                  "inputs": {
                    "add_noise": true,
                    "noise_seed": 0,
                    "cfg": cfg,
                    "model": [
                      "20",
                      0
                    ],
                    "positive": [
                      "6",
                      0
                    ],
                    "negative": [
                      "7",
                      0
                    ],
                    "sampler": [
                      "14",
                      0
                    ],
                    "sigmas": [
                      "22",
                      0
                    ],
                    "latent_image": [
                      "5",
                      0
                    ]
                  },
                  "class_type": "SamplerCustom"
                },
                "14": {
                  "inputs": {
                    "sampler_name": sampler
                  },
                  "class_type": "KSamplerSelect",
                },
                "20": {
                  "inputs": {
                    "ckpt_name": "sd_xl_turbo_1.0_fp16.safetensors"
                  },
                  "class_type": "CheckpointLoaderSimple"
                },
                "22": {
                  "inputs": {
                    "steps": steps,
                    "denoise": 1,
                    "model": [
                      "20",
                      0
                    ]
                  },
                  "class_type": "SDTurboScheduler"
                },
                "19": {
                  "inputs": {
                    "filename_prefix": "ComfyUI",
                    "images": [
                      "8",
                      0
                    ]
                  },
                  "class_type": "SaveImage"
                }
            }

            const workflowSDXL = {
                "4": {
                  "inputs": {
                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                  },
                  "class_type": "CheckpointLoaderSimple"
                },
                "5": {
                  "inputs": {
                    "width": 1024,
                    "height": 1024,
                    "batch_size": 1
                  },
                  "class_type": "EmptyLatentImage"
                },
                "6": {
                  "inputs": {
                    "text": promptP,
                    "clip": [
                      "4",
                      1
                    ]
                  },
                  "class_type": "CLIPTextEncode"
                },
                "7": {
                  "inputs": {
                    "text": promptN,
                    "clip": [
                      "4",
                      1
                    ]
                  },
                  "class_type": "CLIPTextEncode"
                },
                "10": {
                  "inputs": {
                    "add_noise": "enable",
                    "noise_seed": 721897303308196,
                    "steps": stepsRefine+steps,
                    "cfg": cfg,
                    "sampler_name": sampler,
                    "scheduler": "normal",
                    "start_at_step": 0,
                    "end_at_step": steps,
                    "return_with_leftover_noise": "enable",
                    "model": [
                      "4",
                      0
                    ],
                    "positive": [
                      "6",
                      0
                    ],
                    "negative": [
                      "7",
                      0
                    ],
                    "latent_image": [
                      "5",
                      0
                    ]
                  },
                  "class_type": "KSamplerAdvanced"
                },
                "11": {
                  "inputs": {
                    "add_noise": "disable",
                    "noise_seed": 0,
                    "steps": stepsRefine+steps,
                    "cfg": cfg,
                    "sampler_name": sampler,
                    "scheduler": "normal",
                    "start_at_step": steps,
                    "end_at_step": 10000,
                    "return_with_leftover_noise": "disable",
                    "model": [
                      "12",
                      0
                    ],
                    "positive": [
                      "15",
                      0
                    ],
                    "negative": [
                      "16",
                      0
                    ],
                    "latent_image": [
                      "10",
                      0
                    ]
                  },
                  "class_type": "KSamplerAdvanced"
                },
                "12": {
                  "inputs": {
                    "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                  },
                  "class_type": "CheckpointLoaderSimple"
                },
                "15": {
                  "inputs": {
                    "text": promptP,
                    "clip": [
                      "12",
                      1
                    ]
                  },
                  "class_type": "CLIPTextEncode"
                },
                "16": {
                  "inputs": {
                    "text": promptN,
                    "clip": [
                      "12",
                      1
                    ]
                  },
                  "class_type": "CLIPTextEncode"
                },
                "17": {
                  "inputs": {
                    "samples": [
                      "11",
                      0
                    ],
                    "vae": [
                      "12",
                      2
                    ]
                  },
                  "class_type": "VAEDecode"
                },
                "19": {
                  "inputs": {
                    "filename_prefix": "ComfyUI",
                    "images": [
                      "17",
                      0
                    ]
                  },
                  "class_type": "SaveImage"
                }
            }
        
            const workflowSD35 = {
                "3": {
                    "class_type": "KSampler",
                    "inputs": {
                        "cfg": cfg,
                        "denoise": 1,
                        "latent_image": ["5", 0],
                        "model": ["4", 0],
                        "negative": ["7", 0],
                        "positive": ["6", 0],
                        "sampler_name": sampler,
                        "scheduler": "normal",
                        "seed": 8566257,
                        "steps": steps
                    }
                },
                "4": {
                    "class_type": "CheckpointLoaderSimple",
                    "inputs": {
                        "ckpt_name": "sd3.5_large_fp8_scaled.safetensors"
                    }
                },
                "5": {
                    "class_type": "EmptyLatentImage",
                    "inputs": {
                        "batch_size": 1,
                        "height": 1024,
                        "width": 1024
                    }
                },
                "6": {
                    "class_type": "CLIPTextEncode",
                    "inputs": {
                        "clip": ["4", 1],
                        "text": promptP
                    }
                },
                "7": {
                    "class_type": "CLIPTextEncode",
                    "inputs": {
                        "clip": ["4", 1],
                        "text": promptN
                    }
                },
                "8": {
                    "class_type": "VAEDecode",
                    "inputs": {
                        "samples": ["3", 0],
                        "vae": ["4", 2]
                    }
                },
                "9": {
                    "class_type": "SaveImage",
                    "inputs": {
                        "filename_prefix": "ComfyUI",
                        "images": ["8", 0]
                    }
                }
            }
            if (document.getElementById('modelSelect').value === 'sd_xl_base_1.0.safetensors') {
                generateImage(workflowSDXL);
            }
            if (document.getElementById('modelSelect').value === 'sd3.5_large_fp8_scaled.safetensors') {
                generateImage(workflowSD35);
            }
            if (document.getElementById('modelSelect').value === 'sd_xl_turbo_1.0_fp16.safetensors') {
                generateImage(workflowSDXLTurbo);
            }
        }
        async function generateImage(workflow) {
            try {
                // Wysłanie zapytania do kolejki serwera ComfyUI
                const result = await client.enqueue(workflow, {
                    progress: ({max,value}) => updateProgressBar(value, max),
                }
                );
            
                // Sprawdzenie, czy odpowiedź zawiera dane obrazu
                if (!result || !result.images || result.images.length === 0) {
                    throw new Error('No image data returned from the server.');
                }
                console.log(result)
                // Wydobycie adresu URL obrazu z odpowiedzi
                const imageUrl = result.images[0].data;
            
                const img = document.createElement('img');
                img.src = imageUrl;
            
                // Obsługa błędów
                img.onerror = () => {
                    alert('Failed to load the generated image. Please check the server response.');
                };
            
                // Wyświetlenie nowego obrazu
                const outputDiv = document.getElementById('output');
                outputDiv.innerHTML = '';
                outputDiv.appendChild(img);
            } catch (error) {
                console.error('Error generating image:', error);
                alert('Failed to generate image. Check the console for details.');
            }
        }

        document.getElementById('submitButton').addEventListener('click', validateInputs);
        document.getElementById('modelSelect').addEventListener('change', changeModel);
    </script>
</body>
</html>